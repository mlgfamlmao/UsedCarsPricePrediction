{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8399bd5",
   "metadata": {},
   "source": [
    "Bharat Nandan Bodala.  github- @mlgfamlmao\n",
    "\n",
    "\n",
    "PROBLEM CASE -  predict price value of a car based on a set of features.\n",
    "\n",
    "features- {\n",
    "dateCrawled: Date the car was crawled. (Date)\n",
    "name: Name of the car. (String)\n",
    "seller: Type of seller (private or dealer). (String)\n",
    "offerType: Type of offer (e.g. sale, repair, etc.). (String)\n",
    "price: Price of the car. (Integer)\n",
    "abtest: Test type (A or B). (String)\n",
    "vehicleType: Type of vehicle (e.g. SUV, sedan, etc.). (String)\n",
    "yearOfRegistration: Year the car was registered. (Integer)\n",
    "gearbox: Type of gearbox (manual or automatic). (String)\n",
    "powerPS: Power of the car in PS. (Integer)\n",
    "model: Model of the car. (String)\n",
    "kilometer: Kilometers the car has been driven. (Integer)\n",
    "monthOfRegistration: Month the car was registered. (Integer)\n",
    "fuelType: Type of fuel (e.g. diesel, petrol, etc.). (String)\n",
    "brand: Brand of the car. (String)\n",
    "notRepairedDamage: Whether or not the car has any damage that has not been repaired. (String)\n",
    "dateCreated: Date the car was created. (Date)\n",
    "nrOfPictures: Number of pictures of the car. (Integer)\n",
    "postalCode: Postal code of the car. (Integer)\n",
    "lastSeen: Date the car was last seen. (Date)\n",
    "}\n",
    "\n",
    "Approach:\n",
    "        -My initial approach was to clean up data (dropped some useless columns such as index etc and removed outlier values.) , and then, I generated correlation matrices and pyplots. \n",
    "        -Many of the features were deemed useless by observation except powerPS.\n",
    "        -Before proceeding to build a model on one feature, I tried to perform 3 bit encoding to vehicleType and binary encoding to gearbox, but again, the data is not good and no type of meaningful polynomial relation is to be found. \n",
    "        -Either ways, I have decided to train a model based on one feature powerPS.\n",
    "        -Initial chosen hyperparameters: epochs= 50, learning_rate= 0.001, batch_size= 500.\n",
    "        -Used a 1 density keras model with gradient descent approach. Used mean squared error loss as convergence metric.\n",
    "        -Since aforementioned keras model has some unexpected bugs, scikit SGD regressor was used. It provided poor results\n",
    "\n",
    "Conclusion:\n",
    "        Poor data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786be1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "import keras\n",
    "import seaborn as sns\n",
    "import kagglehub\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd765191",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= pd.read_csv(\"autos.csv\")\n",
    "dataset[\"gearbox\"]= dataset[\"gearbox\"].apply(lambda x : 1 if x==\"automatik\" else 0)\n",
    "cleaned = dataset.drop(['index'], axis=1)\n",
    "print(cleaned.head(200))\n",
    "print(\"--\")\n",
    "cleaned[\"price\"]= cleaned[\"price\"]/100000\n",
    "print(cleaned['vehicleType'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a41f916",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot(x='vehicleType', y='price', data=cleaned)\n",
    "#too much similarity between vehicleType and prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a7eb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot(x='model', y = 'price', data = cleaned)\n",
    "#too much similarity between model types and prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b04b23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vehicleEncoding():\n",
    "    #Assign each vehicleType to a 3 bit binary number (000,001 etc)\n",
    "    #Idea scrapped as doing this may not be beneficial at all based on aforementioned reasons.\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be6c804",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cleaned.describe())\n",
    "cleaned.corr(numeric_only= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36512ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleaned.drop([\"price\"],axis=1)\n",
    "y= cleaned[\"price\"]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef0baae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(cleaned.head(2000),x_vars=[\"price\",\"powerPS\",\"gearbox\"],y_vars=[\"price\",\"powerPS\",\"gearbox\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5f56cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This method is bringing some errors which i cannot debug; used scikit insetad (next code block).\n",
    "def build_model(learning_rate,num_features):\n",
    "  inputs= keras.Input(shape = (num_features,))\n",
    "  output = keras.layers.Dense(units= 1)(inputs)\n",
    "  model = keras.Model(inputs= inputs, outputs= output)\n",
    "\n",
    "  #compile the model\n",
    "  print(\"Model metrics:\", model.metrics_names)\n",
    "\n",
    "  model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "                loss=\"mean_squared_error\",\n",
    "                metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "  return model\n",
    "\n",
    "def train_model(model, features, label, epochs, batch_size):\n",
    "\n",
    "\n",
    "\n",
    "  history = model.fit(x=features,\n",
    "                      y=label,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs)\n",
    "\n",
    "\n",
    "  trained_weight = model.get_weights()[0]\n",
    "  trained_bias = model.get_weights()[1]\n",
    "\n",
    "  epochs = history.epoch\n",
    "\n",
    "\n",
    "\n",
    "  hist = pd.DataFrame(history.history)\n",
    "\n",
    "\n",
    "  rmse = hist[\"root_mean_squared_error\"]\n",
    "\n",
    "  return trained_weight, trained_bias, epochs, rmse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e01223",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate= 0.001\n",
    "batch_size= 50\n",
    "epochs= 50\n",
    "features= ['powerPS']\n",
    "feature_values = X_train.loc[:, features] \n",
    "label = \"price\"\n",
    "#model = build_model(learning_rate, len(features)) cannot debug??\n",
    "model = SGDRegressor(alpha=0.01, learning_rate='constant', eta0=learning_rate,\n",
    "                     loss='epsilon_insensitive', max_iter=epochs, n_iter_no_change=20, penalty='l2')\n",
    "model.fit(X_train[features], y_train)\n",
    "\n",
    "trained_weight = model.coef_\n",
    "trained_bias = model.intercept_\n",
    "trained_epochs = model.n_iter_\n",
    "# rmse calculation is not done yet, you need to compute it manually\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "rmse = np.sqrt(mean_squared_error(y_train, model.predict(X_train[features])))\n",
    "\n",
    "print(\"Weights:\", trained_weight)\n",
    "print(\"Bias:\", trained_bias)\n",
    "print(\"Epochs:\", trained_epochs)\n",
    "print(\"Final RMSE:\", rmse)\n",
    "\n",
    "joblib.dump(model, 'FinalUsedCarsModel.pkl')\n",
    "\n",
    "\n",
    "#Not going to test on test data. Credit to this decision goes to the poor RMSE value.\n",
    "#Conclusion: poor data.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
